{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neuro (1).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PavlenkoDR/AbstractFab/blob/master/Neuro_Lizka.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ws0gfCeikzb",
        "colab_type": "text"
      },
      "source": [
        "Распознавание цветов (ромашки, розы, подсолнухи, тюльпаны, одуванчики) на изображениях с помощью предварительно обученной нейронной сети VGG16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcZCbKdRitNi",
        "colab_type": "text"
      },
      "source": [
        "Для распознавания используется предварительно обученная сверточная нейронная сеть VGG16.\n",
        "\n",
        "Перед использованием необходимо скачать и подготовить данные для обучения, проверки и тестирования."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dDvKpNHXmAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.python.keras.applications import VGG16\n",
        "from tensorflow.python.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
        "\n",
        "from tensorflow.python.keras.applications import InceptionV3\n",
        "\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q6bZRqlXsTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Задаем seed для повторяемости результатов\n",
        "numpy.random.seed(42)\n",
        "\n",
        "# Загружаем данные\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "# Размер мини-выборки\n",
        "batch_size = 32\n",
        "# Количество классов изображений\n",
        "nb_classes = 10\n",
        "# Количество эпох для обучения\n",
        "nb_epoch = 25\n",
        "# Размер изображений\n",
        "img_rows, img_cols = 32, 32\n",
        "# Количество каналов в изображении: RGB\n",
        "img_channels = 3\n",
        "\n",
        "# Нормализуем данные\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# Преобразуем метки в категории\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QH-YO48AYYy3",
        "colab_type": "text"
      },
      "source": [
        "Загружаем предварительно обученную нейронную сеть"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpsEGunoYZfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16_net = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "# Загружаем предварительно обученную нейронную сеть Inceptionv3\n",
        "#inception_net = InceptionV3(weights='imagenet', include_top=False, input_shape=(32, 32, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJAXWZxuYjgo",
        "colab_type": "text"
      },
      "source": [
        "Создаем составную нейронную сеть на основе VGG16 или inception"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVQE49HlYoJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16_net.summary()\n",
        "#inception_net.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giGnkcjAYmUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "# Добавляем в модель сеть VGG16 вместо слоя\n",
        "model.add(vgg16_net)\n",
        "#model.add(inception_net)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "#model.add(Dense(512, activation='sigmoid'))\n",
        "model.add(Dense(nb_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjL-pLOiYqA5",
        "colab_type": "text"
      },
      "source": [
        "Компилируем составную нейронную сеть"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZjU_DPCYsK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Задаем параметры оптимизации\n",
        "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=1e-6),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ckqFeOrYwsn",
        "colab_type": "text"
      },
      "source": [
        "Создаем генератор изображений\n",
        "Генератор изображений создается на основе класса ImageDataGenerator. Генератор делит значения всех пикселов изображения на 255. - ВОТ ЭТО СКОРЕЕ ВСЕГО НЕ НУЖНО\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MpXsAQzYwew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eDIpbqaZJjL",
        "colab_type": "code",
        "outputId": "654f5450-8392-4715-d7db-716705872d33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        }
      },
      "source": [
        "\n",
        "model.fit(X_train, Y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=nb_epoch,\n",
        "              validation_split=0.1,\n",
        "              shuffle=True,\n",
        "              verbose=2)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/25\n",
            "45000/45000 - 56s - loss: 1.9842 - acc: 0.2951 - val_loss: 1.3243 - val_acc: 0.5774\n",
            "Epoch 2/25\n",
            "45000/45000 - 55s - loss: 1.3716 - acc: 0.5304 - val_loss: 1.0446 - val_acc: 0.6532\n",
            "Epoch 3/25\n",
            "45000/45000 - 55s - loss: 1.1725 - acc: 0.6017 - val_loss: 0.9326 - val_acc: 0.6816\n",
            "Epoch 4/25\n",
            "45000/45000 - 55s - loss: 1.0643 - acc: 0.6415 - val_loss: 0.8597 - val_acc: 0.7018\n",
            "Epoch 5/25\n",
            "45000/45000 - 55s - loss: 0.9896 - acc: 0.6647 - val_loss: 0.8142 - val_acc: 0.7150\n",
            "Epoch 6/25\n",
            "45000/45000 - 55s - loss: 0.9306 - acc: 0.6851 - val_loss: 0.7820 - val_acc: 0.7274\n",
            "Epoch 7/25\n",
            "45000/45000 - 55s - loss: 0.8821 - acc: 0.7048 - val_loss: 0.7468 - val_acc: 0.7380\n",
            "Epoch 8/25\n",
            "45000/45000 - 53s - loss: 0.8498 - acc: 0.7153 - val_loss: 0.7281 - val_acc: 0.7414\n",
            "Epoch 9/25\n",
            "45000/45000 - 55s - loss: 0.8180 - acc: 0.7244 - val_loss: 0.7125 - val_acc: 0.7512\n",
            "Epoch 10/25\n",
            "45000/45000 - 55s - loss: 0.7820 - acc: 0.7383 - val_loss: 0.6926 - val_acc: 0.7548\n",
            "Epoch 11/25\n",
            "45000/45000 - 55s - loss: 0.7570 - acc: 0.7476 - val_loss: 0.6707 - val_acc: 0.7602\n",
            "Epoch 12/25\n",
            "45000/45000 - 55s - loss: 0.7326 - acc: 0.7547 - val_loss: 0.6616 - val_acc: 0.7678\n",
            "Epoch 13/25\n",
            "45000/45000 - 55s - loss: 0.7142 - acc: 0.7610 - val_loss: 0.6449 - val_acc: 0.7722\n",
            "Epoch 14/25\n",
            "45000/45000 - 55s - loss: 0.6941 - acc: 0.7693 - val_loss: 0.6319 - val_acc: 0.7748\n",
            "Epoch 15/25\n",
            "45000/45000 - 55s - loss: 0.6696 - acc: 0.7749 - val_loss: 0.6241 - val_acc: 0.7778\n",
            "Epoch 16/25\n",
            "45000/45000 - 55s - loss: 0.6553 - acc: 0.7809 - val_loss: 0.6125 - val_acc: 0.7852\n",
            "Epoch 17/25\n",
            "45000/45000 - 55s - loss: 0.6373 - acc: 0.7859 - val_loss: 0.6094 - val_acc: 0.7822\n",
            "Epoch 18/25\n",
            "45000/45000 - 55s - loss: 0.6231 - acc: 0.7918 - val_loss: 0.6021 - val_acc: 0.7878\n",
            "Epoch 19/25\n",
            "45000/45000 - 55s - loss: 0.6110 - acc: 0.7956 - val_loss: 0.5932 - val_acc: 0.7930\n",
            "Epoch 20/25\n",
            "45000/45000 - 55s - loss: 0.5929 - acc: 0.8019 - val_loss: 0.5860 - val_acc: 0.7892\n",
            "Epoch 21/25\n",
            "45000/45000 - 55s - loss: 0.5843 - acc: 0.8048 - val_loss: 0.5789 - val_acc: 0.7972\n",
            "Epoch 22/25\n",
            "45000/45000 - 55s - loss: 0.5657 - acc: 0.8105 - val_loss: 0.5720 - val_acc: 0.7972\n",
            "Epoch 23/25\n",
            "45000/45000 - 55s - loss: 0.5535 - acc: 0.8138 - val_loss: 0.5695 - val_acc: 0.8026\n",
            "Epoch 24/25\n",
            "45000/45000 - 53s - loss: 0.5444 - acc: 0.8179 - val_loss: 0.5598 - val_acc: 0.8084\n",
            "Epoch 25/25\n",
            "45000/45000 - 55s - loss: 0.5277 - acc: 0.8242 - val_loss: 0.5621 - val_acc: 0.8042\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f770e3ada20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNuzbEPBZOjk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c869c25b-02d2-41fd-bd32-10b688e5adae"
      },
      "source": [
        "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Точность работы на тестовых данных: 79.59%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}